{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding all Census tracts within a given radius "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import shapes\n",
    "##### Need to install pyshp, dbfread first \n",
    "Command line: pip install pyshp ;  pip install dbfread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapefile\n",
    "from dbfread import DBF\n",
    "import pandas as pd\n",
    "\n",
    "def read_shp(root,shpfile):\n",
    "    \"\"\"\n",
    "    Input\n",
    "        root : Directory folder that includes shapefiles to be used, as a string\n",
    "                ex: 'C:/Users/markl/OneDrive/Documents/GG/shapefiles'\n",
    "        shpfile: Base name of shape file (not including filename extension), as a string\n",
    "                ex: 'census_tx_blockgroup_2017'\n",
    "    Output\n",
    "        shp : Shapefile containing all info from .shp file\n",
    "        dbf: Pandas dataframe including all information from .dbf file\n",
    "    \"\"\"\n",
    "    # Read in shapefile\n",
    "    shp = shapefile.Reader(root+'/'+shpfile) # shapefile base\n",
    "    \n",
    "    # Read in dbf file, create pandas dataframe to store information for all census tracts\n",
    "    dbf = DBF(root + '/' + shpfile + '.dbf')\n",
    "    dbf = pd.DataFrame(iter(dbf))\n",
    "    \n",
    "    return shp, dbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp, dbf = read_shp('C:/Users/markl/OneDrive/Documents/GG/shapefiles','census_tx_blockgroup_2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define centroid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sys import argv\n",
    "import csv\n",
    "\n",
    "\n",
    "def calculate_shape_area(polygon, signed=False):\n",
    "    \n",
    "    \"\"\"Calculate the area of shape\n",
    "    Input\n",
    "        shape: Numeric array of points (longitude, latitude). It is assumed\n",
    "                 to be closed, i.e. first and last points are identical\n",
    "        signed: Optional flag deciding whether returned area retains its sign:\n",
    "                If points are ordered counter clockwise, the signed area\n",
    "                will be positive.\n",
    "                If points are ordered clockwise, it will be negative\n",
    "                Default is False which means that the area is always positive.\n",
    "    Output\n",
    "        area: Area of shape\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure it is numeric\n",
    "    S = np.array(polygon)\n",
    "\n",
    "    # Check input\n",
    "    msg = ('polygon is assumed to consist of coordinate pairs. '\n",
    "           'I got second dimension %i instead of 2' % S.shape[1])\n",
    "    assert S.shape[1] == 2, msg\n",
    "\n",
    "    msg = ('Polygon is assumed to be closed. '\n",
    "           'However first and last coordinates are different: '\n",
    "           '(%f, %f) and (%f, %f)' % (S[0, 0], S[0, 1], S[-1, 0], S[-1, 1]))\n",
    "    #assert np.allclose(S[0, :], S[-1, :]), msg\n",
    "\n",
    "    # Extract x and y coordinates\n",
    "    x = S[:, 0]\n",
    "    y = S[:, 1]\n",
    "\n",
    "    # Area calculation\n",
    "    a = x[:-1] * y[1:]\n",
    "    b = y[:-1] * x[1:]\n",
    "    A = np.sum(a - b) / 2.\n",
    "\n",
    "    # Return signed or unsigned area\n",
    "    if signed:\n",
    "        return A\n",
    "    else:\n",
    "        return abs(A)\n",
    "\n",
    "\n",
    "def calculate_shape_centroid(polygon):\n",
    "    \"\"\"Calculate the centroid of non-self-intersecting shape\n",
    "    Input\n",
    "        shape: Numeric array of points (longitude, latitude). It is assumed\n",
    "                 to be closed, i.e. first and last points are identical\n",
    "    Output\n",
    "        Numeric (1 x 2) array of points representing the centroid\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure it is numeric\n",
    "    S = np.array(polygon)\n",
    "\n",
    "    # Get area - needed to compute centroid\n",
    "    A = calculate_shape_area(S, signed=True)\n",
    "\n",
    "    # Extract x and y coordinates\n",
    "    x = S[:, 0]\n",
    "    y = S[:, 1]\n",
    "\n",
    "    # Exercise: Compute C as shown in http://paulbourke.net/geometry/polyarea\n",
    "    a = x[:-1] * y[1:]\n",
    "    b = y[:-1] * x[1:]\n",
    "\n",
    "    cx = x[:-1] + x[1:]\n",
    "    cy = y[:-1] + y[1:]\n",
    "\n",
    "    Cx = np.sum(cx * (a - b)) / (6. * A)\n",
    "    Cy = np.sum(cy * (a - b)) / (6. * A)\n",
    "\n",
    "    # Create Nx2 array and return\n",
    "    #C = np.array([Cx, Cy])\n",
    "    return Cx, Cy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate centroids for block groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbf_centroids():\n",
    "    # Calculate centroids for all block groups\n",
    "    for index in range(0,len(shp.shapes())):\n",
    "        Cx,Cy = calculate_shape_centroid(shp.shape(index).points)\n",
    "        dbf.loc[index,'Cx_lon'] = Cx  #store in block group dataframe\n",
    "        dbf.loc[index,'Cy_lat'] = Cy\n",
    "        return dbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf.to_excel(root + 'tx_blockgroup_centroids.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define haversine distance function, angle function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, sin, cos, atan2\n",
    "\n",
    "def haversine(startpoint, endpoint):\n",
    "    \"\"\"Calculate the haversine distance between two geocoordinate points\n",
    "    Input\n",
    "        origin: lat1, lon1 - Geocoordinates of origin\n",
    "        destination: lat2, lon2 - Geocoordinates of destination point (centroid of census block)\n",
    "    Output\n",
    "        distance: haversine distance\n",
    "    \"\"\"\n",
    "    lat1, lon1 = startpoint\n",
    "    lat2, lon2 = endpoint\n",
    "    radius = 3959 # radius of earth (km)\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def azimuth(origin, destination):\n",
    "    \"\"\"\n",
    "    Calculates the angle between two points.\n",
    "    The formula used is the following:\n",
    "        θ = atan2(sin(Δlong).cos(lat2),\n",
    "                  cos(lat1).sin(lat2) − sin(lat1).cos(lat2).cos(Δlong))\n",
    "    :Parameters:\n",
    "      - origin: Tuple representing lat, lon of first point\n",
    "      - destination: Tuple representing lat, lon of second point\n",
    "    :Returns:\n",
    "      - Angle in degrees\n",
    "    \"\"\"\n",
    "    if (type(origin) != tuple) or (type(destination) != tuple):\n",
    "        raise TypeError(\"Only tuples are supported as arguments\")\n",
    "\n",
    "    lat1 = math.radians(origin[0])\n",
    "    lat2 = math.radians(destination[0])\n",
    "\n",
    "    diffLong = math.radians(destination[1] - origin[1])\n",
    "\n",
    "    x = math.sin(diffLong) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1)\n",
    "            * math.cos(lat2) * math.cos(diffLong))\n",
    "\n",
    "    initial_bearing = math.atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = math.degrees(initial_bearing)\n",
    "    compass_bearing = (initial_bearing + 360) % 360\n",
    "\n",
    "    return compass_bearing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find blocks within a given radius of store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create table to store census blocks within a given radius of store (will later add census data to this table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks=pd.DataFrame(columns=('store','county','tract','blockgroup','radius','quadrant','distance','angle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in geocoordinates of stores we are gathering data for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:/Users/markl/OneDrive/Documents/GG/' # root folder (directory)\n",
    "stores_file = 'sql_stores.csv'\n",
    "stores = pd.read_csv(root+stores_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbf = pd.read_csv(root + 'tx_blockgroup_centroids.csv',dtype={'TRACTCE':str,'COUNTYFP':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull blocks from a given distance from store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "max_distance = 10   # miles\n",
    "\n",
    "for store_rows  in stores.iterrows():\n",
    "    idx, info = store_rows\n",
    "    origin = stores.loc[idx,'X'],stores.loc[idx,'Y']\n",
    "    \n",
    "    for row in dbf.iterrows():\n",
    "        index, data = row\n",
    "        destination = dbf.loc[index,'Cy_lat'],dbf.loc[index,'Cx_lon']\n",
    "        distance = haversine(origin,destination)\n",
    "        angle = azimuth(origin,destination)\n",
    "    \n",
    "        if distance <= max_distance:\n",
    "            blocks = blocks.append(pd.DataFrame({'store': stores.loc[idx,'Buyer Num'], 'distance': distance, 'angle': angle,\n",
    "                                                 'county': dbf.loc[index,'COUNTYFP'], 'tract': str(dbf.loc[index,'TRACTCE']),\n",
    "                                                 'blockgroup':dbf.loc[index,'BLKGRPCE']}, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_census_blocks(storefile,dbf,max_distance):\n",
    "    \"\"\"\n",
    "    Function to find all census blocks within a max_distance radius of each store in the stores file.\n",
    "    \n",
    "    Inputs\n",
    "        - stores : .csv file containing columns 'X' and 'Y'\n",
    "        - blocks : .dbf file, result of dbf_centroids function. Must contain columns 'Cx_lon' and 'Cy_lat'\n",
    "        - max_distance : Maximum distance to search (speeds up function, so only those blocks within a \n",
    "                         max_distance radius are included)\n",
    "    Output\n",
    "        - dbf : Updated dbf DataFrame, with census blocks grouped by distance (0-1 mi, 3-5 mi, 5-10 mi)\n",
    "                and quadrant (0-90 deg: 1, 90-180 deg: 2, 180-270 deg: 3, 270-360 deg: 4)\n",
    "        \n",
    "                Buyer Num | county | tract | blockgroup | radius | quadrant | distance |    angle\n",
    "            -------------------------------------------------------------------------------------\n",
    "                P913023   |  113   |  7201 |     1      |    1   |     1    | 0.370144 |  86.894711\n",
    "                          |        |       |            |        |          |          |\n",
    "    \"\"\"\n",
    "    \n",
    "    blocks = pd.DataFrame(columns=('store','county','tract','blockgroup','radius','quadrant','distance','angle'))\n",
    "    stores = pd.read_csv(storefile)\n",
    "    \n",
    "    for store_rows  in stores.iterrows():\n",
    "        idx, info = store_rows\n",
    "        origin = stores.loc[idx,'X'],stores.loc[idx,'Y']\n",
    "    \n",
    "        for row in dbf.iterrows():\n",
    "            index, data = row\n",
    "            destination = dbf.loc[index,'Cy_lat'],dbf.loc[index,'Cx_lon']\n",
    "            distance = haversine(origin,destination)\n",
    "            angle = azimuth(origin,destination)\n",
    "    \n",
    "            if distance <= max_distance:\n",
    "                blocks = blocks.append(pd.DataFrame({'store': stores.loc[idx,'Buyer Num'], 'distance': distance, 'angle': angle,\n",
    "                                                 'county': dbf.loc[index,'COUNTYFP'], 'tract': '%06f' % dbf.loc[index,'TRACTCE'],\n",
    "                                                 'blockgroup':dbf.loc[index,'BLKGRPCE']}, index=[0]), ignore_index=True)\n",
    "def block_discrete(blocks):\n",
    "    \"\"\"\n",
    "    Function to discretize continuous distance and angle into chunks\n",
    "    \"\"\"    \n",
    "    for rows in blocks.iterrows():\n",
    "        r,data = rows\n",
    "        if 0.0 <= blocks.loc[r,'distance'] <= 1.0:\n",
    "            blocks.loc[r,'radius'] = 1\n",
    "        elif 1.0 <= blocks.loc[r,'distance'] <= 3.0:\n",
    "            blocks.loc[r,'radius'] = 3\n",
    "        elif 3.0 <= blocks.loc[r,'distance'] <= 5.0:\n",
    "            blocks.loc[r,'radius'] = 5\n",
    "        elif 5.0 <= blocks.loc[r,'distance'] <= 10.0:\n",
    "            blocks.loc[r,'radius'] = 10  \n",
    "            \n",
    "        if 0.0 <= blocks.loc[r,'angle'] <= 90.0:\n",
    "            blocks.loc[r,'quadrant'] = 1\n",
    "        elif 90.0 <= blocks.loc[r,'angle'] <= 180.0:\n",
    "            blocks.loc[r,'quadrant'] = 2\n",
    "        elif 180.0 <= blocks.loc[r,'angle'] <= 270.0:\n",
    "            blocks.loc[r,'quadrant'] = 3\n",
    "        elif 270.0 <= blocks.loc[r,'angle'] <= 360.0:\n",
    "            blocks.loc[r,'quadrant'] = 4\n",
    "    \n",
    "    # Sort values, reorder columns\n",
    "    blocks = blocks.sort_values(by=['store','radius','quadrant','tract','blockgroup'])\n",
    "    blocks = blocks[['store','county','tract','blockgroup','distance','angle','quadrant','radius']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save into csv\n",
    "blocks.to_csv(root+'censusblocks_sql_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here, go to Census API Data for Tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
